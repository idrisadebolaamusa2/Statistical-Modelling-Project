{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liFlBxAKG1vC"
   },
   "source": [
    "Build a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zPmh5Ml7fbtu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "VpV7j7CSfzu2",
    "outputId": "d13e9808-c033-4487-d09b-1909d61b9c04",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reading merged_df csv file\n",
    "\n",
    "df  = pd.read_csv('merged_df.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4WEs4NWlpmgA",
    "outputId": "701df1d7-8364-4b9a-f456-c7d3e6af7ad3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dropping columns that won't be needed for training\n",
    "\n",
    "df = df.drop(['Station Name', 'Business Name', 'Business Address', 'Category'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UkKhZ8YUG1vP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df.drop(\"No. of bikes\" , axis=1)\n",
    "y = df.pop(\"No. of bikes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "cc7rrN7KnnHK",
    "outputId": "36c80efe-5a0d-4c36-aaec-ac76d4f59839",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYq7bzvKntKg",
    "outputId": "e4806a90-146a-4767-91af-72027e97d82c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1wipne3en58Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Adding a constant\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "lin_reg = sm.OLS(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "k7Thmu_8q-aB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Building the model\n",
    "\n",
    "model = lin_reg.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZ-iZSZ6G1vR"
   },
   "source": [
    "Provide model output and an interpretation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rS0JKeSbG1vS",
    "outputId": "39c48ba8-910c-474c-d885-581a0422f979",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_model = model.summary()\n",
    "\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary:\n",
    "# •\tDependent Variable (Dep. Variable): No. of bikes\n",
    "# •\tR-squared (R²): 0.091\n",
    "# o\tThe R-squared value indicates the proportion of the variance in the dependent variable (No. of bikes) that is predictable from the independent variables.\n",
    "# o\tIn this case, approximately 9.1% of the variance in the number of bikes is explained by the independent variables.\n",
    "# •\tAdjusted R-squared (Adj. R²): 0.015\n",
    "# o\tAdjusted R-squared considers the number of predictors in the model, providing a more reliable measure when there are multiple predictors. It penalizes the inclusion of irrelevant variables.\n",
    "# •\tF-statistic (F-statistic): 1.200\n",
    "# o\tThe F-statistic is a measure of how well the entire model explains the variability in the dependent variable.\n",
    "# o\tA higher F-statistic suggests a better fit. Here, it's relatively low.\n",
    "# •\tProb (F-statistic): 0.312\n",
    "# o\tThis is the p-value associated with the F-statistic. A low p-value indicates that the overall regression model is statistically significant. Here, the value is 0.312, suggesting that the model is not statistically significant.\n",
    "# Coefficients Table:\n",
    "# •\tConst (Constant): 1.182e+04 (11,820)\n",
    "# o\tThe constant term in the regression equation when all independent variables are zero.\n",
    "# •\tCoefficients for Independent Variables (e.g., Latitude, Longitude, etc.):\n",
    "# o\tEach coefficient represents the change in the dependent variable for a one-unit change in the corresponding independent variable, holding other variables constant.\n",
    "# •\tP>|t| (p-value):\n",
    "# o\tThe p-value associated with each coefficient. It tests the null hypothesis that the corresponding coefficient is equal to zero (no effect).\n",
    "# o\tA low p-value (typically less than 0.05) indicates that the variable is statistically significant.\n",
    "# Additional Information:\n",
    "# •\tOmnibus: A test of the normality of residuals. A low p-value suggests that the residuals are not normally distributed.\n",
    "# •\tDurbin-Watson: A test for autocorrelation of residuals. Values close to 2 suggest no autocorrelation.\n",
    "# •\tJarque-Bera (JB): Another test for normality. A low p-value suggests non-normality.\n",
    "# •\tSkewness (Skew): A measure of the asymmetry of the residuals.\n",
    "# •\tKurtosis: A measure of the \"tailedness\" of the residuals.\n",
    "# •\tCond. No. (Condition Number): A measure of multicollinearity. Values greater than 20 may indicate a problematic amount of collinearity.\n",
    "# Interpretation:\n",
    "# •\tThe R-squared is relatively low (9.1%), indicating that the model explains a small portion of the variability in the number of bikes.\n",
    "# •\tThe p-values associated with coefficients should be checked to determine which variables are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2uG5G6QG1vT"
   },
   "source": [
    "# Stretch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvGteNsAG1vU"
   },
   "source": [
    "How can you turn the regression model into a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To turn a regression model into a classification model, one needs to define a threshold or cutoff point, and then predict whether the outcome falls above or below that threshold. This usually involves converting the continuous output of the regression model into discrete categories. Here's a general step-by-step approach:\n",
    "# 1.\tDefine Categories:\n",
    "# o\tDecide on the categories you want to predict. For example, you might want to predict whether the number of bikes is \"High\" or \"Low.\"\n",
    "# 2.\tChoose a Threshold:\n",
    "# o\tDetermine a threshold value that separates the categories. This could be based on domain knowledge, business requirements, or a statistical criterion.\n",
    "# 3.\tCreate Binary Outcome:\n",
    "# o\tCreate a new binary outcome variable based on whether the predicted value from the regression model is above or below the chosen threshold.\n",
    "# o\tExample: If predicted value > Threshold, assign category \"High,\" else assign category \"Low.\"\n",
    "# 4.\tTrain a Classification Model:\n",
    "# o\tUse the binary outcome as the dependent variable and the same set of independent variables from the regression model.\n",
    "# o\tChoose a suitable classification algorithm (e.g., logistic regression, decision tree, random forest) and train the model on the binary outcome.\n",
    "# 5.\tEvaluate the Classification Model:\n",
    "# o\tAssess the performance of the classification model using standard classification metrics (accuracy, precision, recall, F1-score, etc.).\n",
    "# o\tSplit your data into training and testing sets to evaluate the model on unseen data.\n",
    "\n",
    "# To be more specific for our data set, we can do the following;\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Assuming df is the DataFrame with the regression results\n",
    "# Let's say I want to predict if the number of bikes is \"High\" (1) or \"Low\" (0)\n",
    "threshold = 12000  # Choose an appropriate threshold\n",
    "# Create a binary outcome variable\n",
    "df['BikeCategory'] = np.where(df['PredictedNumberofBikes'] > threshold, 1, 0)\n",
    "# Define features (independent variables) and target (dependent variable)\n",
    "X = df[['Latitude', 'Longitude', 'Distance', 'Review Count', 'Rating']]\n",
    "y = df['BikeCategory']\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Train a logistic regression model (one can choose another classification algorithm)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
